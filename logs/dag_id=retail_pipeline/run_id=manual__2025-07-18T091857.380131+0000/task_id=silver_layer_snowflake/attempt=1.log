{"timestamp":"2025-07-18T09:19:13.767577","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-18T09:19:13.768115","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/upload_to_hdfs_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-18T09:19:13.787085","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:13.787777","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'docker exec retail-spark-master                        /opt/bitnami/spark/bin/spark-submit                        --master spark://spark-master:7077 /opt/spark-apps/scripts/snowflake_staging.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:13.796186","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.027288","level":"info","event":"25/07/18 09:19:16 INFO SparkContext: Running Spark version 3.4.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.052499","level":"info","event":"25/07/18 09:19:16 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.052738","level":"info","event":"25/07/18 09:19:16 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.052847","level":"info","event":"25/07/18 09:19:16 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.054180","level":"info","event":"25/07/18 09:19:16 INFO SparkContext: Submitted application: Retail_Snowflake_Staging","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.073178","level":"info","event":"25/07/18 09:19:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.079900","level":"info","event":"25/07/18 09:19:16 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.080291","level":"info","event":"25/07/18 09:19:16 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.122781","level":"info","event":"25/07/18 09:19:16 INFO SecurityManager: Changing view acls to: spark","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.122994","level":"info","event":"25/07/18 09:19:16 INFO SecurityManager: Changing modify acls to: spark","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.123139","level":"info","event":"25/07/18 09:19:16 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.123646","level":"info","event":"25/07/18 09:19:16 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.124016","level":"info","event":"25/07/18 09:19:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.179461","level":"info","event":"25/07/18 09:19:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.374266","level":"info","event":"25/07/18 09:19:16 INFO Utils: Successfully started service 'sparkDriver' on port 45693.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.394805","level":"info","event":"25/07/18 09:19:16 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.429907","level":"info","event":"25/07/18 09:19:16 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.452620","level":"info","event":"25/07/18 09:19:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.452822","level":"info","event":"25/07/18 09:19:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.457213","level":"info","event":"25/07/18 09:19:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.476568","level":"info","event":"25/07/18 09:19:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-596957f2-4f5f-41db-8489-78d56d696d5b","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.491178","level":"info","event":"25/07/18 09:19:16 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.507980","level":"info","event":"25/07/18 09:19:16 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.604763","level":"info","event":"25/07/18 09:19:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.648029","level":"info","event":"25/07/18 09:19:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.742772","level":"info","event":"25/07/18 09:19:16 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://retail-spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.770245","level":"info","event":"25/07/18 09:19:16 INFO TransportClientFactory: Successfully created connection to retail-spark-master/172.24.0.4:7077 after 15 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.833127","level":"info","event":"25/07/18 09:19:16 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250718091916-0008","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.834991","level":"info","event":"25/07/18 09:19:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250718091916-0008/0 on worker-20250718090909-172.24.0.6-42597 (172.24.0.6:42597) with 12 core(s)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.836972","level":"info","event":"25/07/18 09:19:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20250718091916-0008/0 on hostPort 172.24.0.6:42597 with 12 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.838432","level":"info","event":"25/07/18 09:19:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41325.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.838596","level":"info","event":"25/07/18 09:19:16 INFO NettyBlockTransferService: Server created on 8da053d44e9f:41325","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.840542","level":"info","event":"25/07/18 09:19:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.845207","level":"info","event":"25/07/18 09:19:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 8da053d44e9f, 41325, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.848442","level":"info","event":"25/07/18 09:19:16 INFO BlockManagerMasterEndpoint: Registering block manager 8da053d44e9f:41325 with 434.4 MiB RAM, BlockManagerId(driver, 8da053d44e9f, 41325, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.850674","level":"info","event":"25/07/18 09:19:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 8da053d44e9f, 41325, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.851940","level":"info","event":"25/07/18 09:19:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 8da053d44e9f, 41325, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:16.861803","level":"info","event":"25/07/18 09:19:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250718091916-0008/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:17.011384","level":"info","event":"25/07/18 09:19:17 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:17.230675","level":"info","event":"25/07/18 09:19:17 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:17.237398","level":"info","event":"25/07/18 09:19:17 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:18.544396","level":"info","event":"25/07/18 09:19:18 INFO InMemoryFileIndex: It took 80 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:18.627872","level":"info","event":"25/07/18 09:19:18 INFO InMemoryFileIndex: It took 33 ms to list leaf files for 12 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:18.837210","level":"info","event":"25/07/18 09:19:18 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.24.0.6:50980) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:18.906359","level":"info","event":"25/07/18 09:19:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.24.0.6:35799 with 434.4 MiB RAM, BlockManagerId(0, 172.24.0.6, 35799, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:20.410963","level":"info","event":"25/07/18 09:19:20 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:20.412981","level":"info","event":"25/07/18 09:19:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:20.826943","level":"info","event":"25/07/18 09:19:20 INFO CodeGenerator: Code generated in 152.045056 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:20.867095","level":"info","event":"25/07/18 09:19:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.3 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:20.915865","level":"info","event":"25/07/18 09:19:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:20.919156","level":"info","event":"25/07/18 09:19:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 8da053d44e9f:41325 (size: 34.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:20.922482","level":"info","event":"25/07/18 09:19:20 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:20.931965","level":"info","event":"25/07/18 09:19:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7036754 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.028481","level":"info","event":"25/07/18 09:19:21 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.045416","level":"info","event":"25/07/18 09:19:21 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.045632","level":"info","event":"25/07/18 09:19:21 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.045727","level":"info","event":"25/07/18 09:19:21 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.045792","level":"info","event":"25/07/18 09:19:21 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.050510","level":"info","event":"25/07/18 09:19:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.106898","level":"info","event":"25/07/18 09:19:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.1 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.112620","level":"info","event":"25/07/18 09:19:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.113853","level":"info","event":"25/07/18 09:19:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 8da053d44e9f:41325 (size: 6.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.114269","level":"info","event":"25/07/18 09:19:21 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.129736","level":"info","event":"25/07/18 09:19:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.130692","level":"info","event":"25/07/18 09:19:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.162886","level":"info","event":"25/07/18 09:19:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.24.0.6, executor 0, partition 0, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.343895","level":"info","event":"25/07/18 09:19:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.24.0.6:35799 (size: 6.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:21.916727","level":"info","event":"25/07/18 09:19:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.24.0.6:35799 (size: 34.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.428018","level":"info","event":"25/07/18 09:19:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1274 ms on 172.24.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.429729","level":"info","event":"25/07/18 09:19:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.435501","level":"info","event":"25/07/18 09:19:22 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 1.373 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.438128","level":"info","event":"25/07/18 09:19:22 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.438331","level":"info","event":"25/07/18 09:19:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.441023","level":"info","event":"25/07/18 09:19:22 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 1.412051 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.462635","level":"info","event":"25/07/18 09:19:22 INFO CodeGenerator: Code generated in 10.897569 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.497884","level":"info","event":"25/07/18 09:19:22 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.498058","level":"info","event":"25/07/18 09:19:22 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.504466","level":"info","event":"25/07/18 09:19:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 199.3 KiB, free 434.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.517927","level":"info","event":"25/07/18 09:19:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.524649","level":"info","event":"25/07/18 09:19:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 8da053d44e9f:41325 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.525442","level":"info","event":"25/07/18 09:19:22 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.527517","level":"info","event":"25/07/18 09:19:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7036754 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.531174","level":"info","event":"25/07/18 09:19:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 8da053d44e9f:41325 in memory (size: 6.0 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.538205","level":"info","event":"25/07/18 09:19:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.24.0.6:35799 in memory (size: 6.0 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.612607","level":"info","event":"25/07/18 09:19:22 WARN SnowflakeConnectorUtils$: Query pushdown is not supported because you are using Spark 3.4.0 with a connector designed to support Spark 3.3. Either use the version of Spark supported by the connector or install a version of the connector that supports your version of Spark.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.627611","level":"info","event":"25/07/18 09:19:22 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.627755","level":"info","event":"25/07/18 09:19:22 INFO FileSourceStrategy: Post-Scan Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.632768","level":"info","event":"25/07/18 09:19:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 199.2 KiB, free 433.7 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.641226","level":"info","event":"25/07/18 09:19:22 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 8da053d44e9f:41325 in memory (size: 34.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.644114","level":"info","event":"25/07/18 09:19:22 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.24.0.6:35799 in memory (size: 34.2 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.644326","level":"info","event":"25/07/18 09:19:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.644946","level":"info","event":"25/07/18 09:19:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 8da053d44e9f:41325 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.646303","level":"info","event":"25/07/18 09:19:22 INFO SparkContext: Created broadcast 3 from rdd at SnowflakeWriter.scala:87","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.652426","level":"info","event":"25/07/18 09:19:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 7036754 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:22.697642","level":"info","event":"25/07/18 09:19:22 WARN ServerConnection$: JDBC 3.13.31 is being used. But the certified JDBC version 3.13.30 is recommended.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.942463","level":"info","event":"25/07/18 09:19:24 INFO ServerConnection$: Create ServerConnection with new JDBC connection: 182007829172298","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.964382","level":"info","event":"25/07/18 09:19:24 INFO SparkConnectorContext$: Spark Connector system config: {","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.964691","level":"info","event":"  \"spark_connector_version\" : \"2.12.0\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.964837","level":"info","event":"  \"spark_version\" : \"3.4.0\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.964948","level":"info","event":"  \"application_name\" : \"Retail_Snowflake_Staging\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965034","level":"info","event":"  \"scala_version\" : \"2.12.17\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965123","level":"info","event":"  \"java_version\" : \"17.0.7\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965204","level":"info","event":"  \"jdbc_version\" : \"3.13.31\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965272","level":"info","event":"  \"certified_jdbc_version\" : \"3.13.30\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965337","level":"info","event":"  \"os_name\" : \"Linux\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965403","level":"info","event":"  \"max_memory_in_mb\" : 1024,","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965449","level":"info","event":"  \"total_memory_in_mb\" : 174,","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965532","level":"info","event":"  \"free_memory_in_mb\" : 71,","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965578","level":"info","event":"  \"cpu_cores\" : 12,","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965621","level":"info","event":"  \"spark_application_id\" : \"app-20250718091916-0008\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965673","level":"info","event":"  \"spark_language\" : \"Scala\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965721","level":"info","event":"  \"is_pyspark\" : false,","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965770","level":"info","event":"  \"spark_config\" : {","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965830","level":"info","event":"    \"spark.app.submitTime\" : \"N/A\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.965936","level":"info","event":"    \"spark.sql.warehouse.dir\" : \"N/A\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966012","level":"info","event":"    \"spark.app.name\" : \"Retail_Snowflake_Staging\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966081","level":"info","event":"    \"spark.executor.id\" : \"driver\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966143","level":"info","event":"    \"spark.app.id\" : \"app-20250718091916-0008\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966205","level":"info","event":"    \"spark.driver.host\" : \"8da053d44e9f\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966319","level":"info","event":"    \"spark.driver.port\" : \"N/A\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966426","level":"info","event":"    \"spark.driver.extraJavaOptions\" : \"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false --add-exports java.base/sun.nio.ch=ALL-UNNAMED\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966516","level":"info","event":"    \"spark.rdd.compress\" : \"N/A\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966563","level":"info","event":"    \"spark.serializer.objectStreamReset\" : \"N/A\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966611","level":"info","event":"    \"spark.app.startTime\" : \"N/A\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966654","level":"info","event":"    \"spark.submit.pyFiles\" : \"N/A\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966688","level":"info","event":"    \"spark.submit.deployMode\" : \"client\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966724","level":"info","event":"    \"spark.master\" : \"spark://retail-spark-master:7077\",","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966802","level":"info","event":"    \"spark.executor.extraJavaOptions\" : \"-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966860","level":"info","event":"  },","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966897","level":"info","event":"  \"libraries\" : [ \"py4j\", \"py4j.commands\", \"py4j.reflection\" ],","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966935","level":"info","event":"  \"dependencies\" : [ ],","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.966985","level":"info","event":"  \"cluster_node_count\" : 2,","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.967023","level":"info","event":"  \"spark_default_parallelism\" : 12,","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.967076","level":"info","event":"  \"deploy_mode\" : \"client\"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.967244","level":"info","event":"}","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:24.976559","level":"info","event":"25/07/18 09:19:24 INFO SnowflakeSQLStatement: Spark Connector Master: execute query with bind variable: alter session set timezone = 'Etc/UTC' , timestamp_ntz_output_format = 'YYYY-MM-DD HH24:MI:SS.FF3', timestamp_ltz_output_format = 'TZHTZM YYYY-MM-DD HH24:MI:SS.FF3', timestamp_tz_output_format = 'TZHTZM YYYY-MM-DD HH24:MI:SS.FF3' ;","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:25.674011","level":"info","event":"25/07/18 09:19:25 INFO SnowflakeSQLStatement: Spark Connector Master: execute query with bind variable: create  temporary stage if not exists identifier(?)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:26.594544","level":"info","event":"25/07/18 09:19:26 INFO CloudStorageOperations$: Spark Connector Master: Begin to process and upload data for 11 partitions: directory=Gr6700hNAE CSV true","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:26.594732","level":"info","event":"25/07/18 09:19:26 INFO CloudStorageOperations$: Spark Connector Master: Begin to retrieve pre-signed URL or down-scoped token for 11 files by calling PUT command.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.031757","level":"info","event":"25/07/18 09:19:27 INFO CloudStorageOperations$: Spark Connector Master: Upload file to GCP with down-scoped token instead of pre-signed URL.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.033309","level":"info","event":"25/07/18 09:19:27 INFO CloudStorageOperations$: Spark Connector Master: Time to retrieve down-scoped token for 1/11 files is 436 ms.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.094681","level":"info","event":"25/07/18 09:19:27 INFO SparkContext: Starting job: collect at CloudStorageOperations.scala:1862","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.095695","level":"info","event":"25/07/18 09:19:27 INFO DAGScheduler: Got job 1 (collect at CloudStorageOperations.scala:1862) with 11 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.095861","level":"info","event":"25/07/18 09:19:27 INFO DAGScheduler: Final stage: ResultStage 1 (collect at CloudStorageOperations.scala:1862)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.095948","level":"info","event":"25/07/18 09:19:27 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.096014","level":"info","event":"25/07/18 09:19:27 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.096923","level":"info","event":"25/07/18 09:19:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[16] at mapPartitionsWithIndex at CloudStorageOperations.scala:1839), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.101057","level":"info","event":"25/07/18 09:19:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 33.5 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.102973","level":"info","event":"25/07/18 09:19:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 18.1 KiB, free 433.9 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.103816","level":"info","event":"25/07/18 09:19:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 8da053d44e9f:41325 (size: 18.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.104367","level":"info","event":"25/07/18 09:19:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1535","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.104984","level":"info","event":"25/07/18 09:19:27 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 1 (MapPartitionsRDD[16] at mapPartitionsWithIndex at CloudStorageOperations.scala:1839) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.105073","level":"info","event":"25/07/18 09:19:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 11 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.107079","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.24.0.6, executor 0, partition 0, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.107270","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (172.24.0.6, executor 0, partition 1, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.107659","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (172.24.0.6, executor 0, partition 2, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.108158","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (172.24.0.6, executor 0, partition 3, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.108415","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5) (172.24.0.6, executor 0, partition 4, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.108681","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 6) (172.24.0.6, executor 0, partition 5, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.109913","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 7) (172.24.0.6, executor 0, partition 6, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.110629","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 8) (172.24.0.6, executor 0, partition 7, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.111837","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 9) (172.24.0.6, executor 0, partition 8, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.112413","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 10) (172.24.0.6, executor 0, partition 9, ANY, 7992 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.113217","level":"info","event":"25/07/18 09:19:27 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 11) (172.24.0.6, executor 0, partition 10, ANY, 8152 bytes)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:27.149878","level":"info","event":"25/07/18 09:19:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.24.0.6:35799 (size: 18.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.401856","level":"info","event":"25/07/18 09:19:28 ERROR Inbox: Ignoring error","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402057","level":"info","event":"java.io.NotSerializableException: org.apache.spark.storage.StorageStatus","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402121","level":"info","event":"Serialization stack:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402165","level":"info","event":"\t- object not serializable (class: org.apache.spark.storage.StorageStatus, value: org.apache.spark.storage.StorageStatus@4ce02182)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402203","level":"info","event":"\t- element of array (index: 0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402238","level":"info","event":"\t- array (class [Lorg.apache.spark.storage.StorageStatus;, size 2)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402271","level":"info","event":"\tat org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:41)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402308","level":"info","event":"\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:49)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402363","level":"info","event":"\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402409","level":"info","event":"\tat org.apache.spark.rpc.netty.NettyRpcEnv.serialize(NettyRpcEnv.scala:286)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402470","level":"info","event":"\tat org.apache.spark.rpc.netty.RemoteNettyRpcCallContext.send(NettyRpcCallContext.scala:64)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402509","level":"info","event":"\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402543","level":"info","event":"\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:162)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402576","level":"info","event":"\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402608","level":"info","event":"\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402642","level":"info","event":"\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402673","level":"info","event":"\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402704","level":"info","event":"\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402733","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402763","level":"info","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.402794","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:833)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:28.491680","level":"info","event":"25/07/18 09:19:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.24.0.6:35799 (size: 34.2 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:43.056164","level":"info","event":"25/07/18 09:19:43 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 10) in 15943 ms on 172.24.0.6 (executor 0) (1/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:45.980056","level":"info","event":"25/07/18 09:19:45 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 11) in 18867 ms on 172.24.0.6 (executor 0) (2/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:46.967350","level":"info","event":"25/07/18 09:19:46 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 19858 ms on 172.24.0.6 (executor 0) (3/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:47.219592","level":"info","event":"25/07/18 09:19:47 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 20111 ms on 172.24.0.6 (executor 0) (4/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:47.467260","level":"info","event":"25/07/18 09:19:47 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 6) in 20358 ms on 172.24.0.6 (executor 0) (5/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:48.102619","level":"info","event":"25/07/18 09:19:48 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 9) in 20991 ms on 172.24.0.6 (executor 0) (6/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:48.113180","level":"info","event":"25/07/18 09:19:48 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 21005 ms on 172.24.0.6 (executor 0) (7/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:48.161188","level":"info","event":"25/07/18 09:19:48 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 7) in 21051 ms on 172.24.0.6 (executor 0) (8/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:48.385179","level":"info","event":"25/07/18 09:19:48 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 8) in 21276 ms on 172.24.0.6 (executor 0) (9/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:48.444956","level":"info","event":"25/07/18 09:19:48 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 21337 ms on 172.24.0.6 (executor 0) (10/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:49.750732","level":"info","event":"25/07/18 09:19:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 22644 ms on 172.24.0.6 (executor 0) (11/11)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:49.750939","level":"info","event":"25/07/18 09:19:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:49.751432","level":"info","event":"25/07/18 09:19:49 INFO DAGScheduler: ResultStage 1 (collect at CloudStorageOperations.scala:1862) finished in 22.652 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:49.751574","level":"info","event":"25/07/18 09:19:49 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:49.751788","level":"info","event":"25/07/18 09:19:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:49.751878","level":"info","event":"25/07/18 09:19:49 INFO DAGScheduler: Job 1 finished: collect at CloudStorageOperations.scala:1862, took 22.657403 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:49.754601","level":"info","event":"25/07/18 09:19:49 INFO CloudStorageOperations$: Spark Connector Master: Finish uploading data for 11 partitions in 23.16 seconds.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:49.755349","level":"info","event":"25/07/18 09:19:49 INFO StageWriter$: writeToTableWithStagingTable: check table existence with \"RETAIL_SALES\".\"STAGING\".SILVER_DATA for SILVER_DATA","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:49.756156","level":"info","event":"25/07/18 09:19:49 INFO SnowflakeSQLStatement: Spark Connector Master: execute query with bind variable: desc table identifier(?)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:49.930544","level":"info","event":"25/07/18 09:19:49 INFO SnowflakeSQLStatement: Spark Connector Master: execute query with bind variable: create   table if not exists identifier(?) (\"_C0\" STRING ,\"_C1\" STRING ,\"_C2\" STRING ,\"_C3\" STRING ,\"_C4\" STRING ,\"_C5\" STRING ,\"_C6\" STRING ,\"_C7\" STRING ,\"_C8\" STRING ,\"_C9\" STRING )","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.214876","level":"info","event":"25/07/18 09:19:50 INFO StageWriter$: Begin to write at 2025-07-18T09:19:50.203730908 (Coordinated Universal Time)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.215467","level":"info","event":"25/07/18 09:19:50 INFO StageWriter$: Total file count is 11, non-empty files count is 11, total file size is 39.84 MB, total row count is 397.29 KB.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.218788","level":"info","event":"25/07/18 09:19:50 INFO StageWriter$: Now executing below command to write into table:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.218955","level":"info","event":"copy into SILVER_DATA_staging_1635685801 FROM @spark_connector_load_stage_x3fBDZ2zx4/Gr6700hNAE/","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219007","level":"info","event":"FILE_FORMAT = (","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219049","level":"info","event":"    TYPE=CSV","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219087","level":"info","event":"    FIELD_DELIMITER='|'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219125","level":"info","event":"    NULL_IF=()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219167","level":"info","event":"    FIELD_OPTIONALLY_ENCLOSED_BY='\"'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219195","level":"info","event":"    TIMESTAMP_FORMAT='TZHTZM YYYY-MM-DD HH24:MI:SS.FF9'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219219","level":"info","event":"    DATE_FORMAT='TZHTZM YYYY-MM-DD HH24:MI:SS.FF9'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219249","level":"info","event":"    BINARY_FORMAT=BASE64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219300","level":"info","event":"  )","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219327","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219356","level":"info","event":"25/07/18 09:19:50 INFO SnowflakeSQLStatement: Spark Connector Master: execute query with bind variable: copy into SILVER_DATA_staging_1635685801 FROM @spark_connector_load_stage_x3fBDZ2zx4/Gr6700hNAE/","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219382","level":"info","event":"FILE_FORMAT = (","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219413","level":"info","event":"    TYPE=CSV","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219436","level":"info","event":"    FIELD_DELIMITER='|'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219458","level":"info","event":"    NULL_IF=()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219483","level":"info","event":"    FIELD_OPTIONALLY_ENCLOSED_BY='\"'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219507","level":"info","event":"    TIMESTAMP_FORMAT='TZHTZM YYYY-MM-DD HH24:MI:SS.FF9'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219529","level":"info","event":"    DATE_FORMAT='TZHTZM YYYY-MM-DD HH24:MI:SS.FF9'","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219550","level":"info","event":"    BINARY_FORMAT=BASE64","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219576","level":"info","event":"  )","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.219603","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.318467","level":"info","event":"25/07/18 09:19:50 INFO SparkConnectorContext$: Spark connector register listener for: app-20250718091916-0008","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.320206","level":"info","event":"25/07/18 09:19:50 INFO SparkConnectorContext$: Add running query for app-20250718091916-0008 session: 182007829172298 queryId: 01bdc48f-0000-a176-0000-a58900013316","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.322279","level":"info","event":"25/07/18 09:19:50 INFO StageWriter$: The query ID for async writing into table command is: 01bdc48f-0000-a176-0000-a58900013316; The query ID URL is:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:50.322497","level":"info","event":"https://TRLIYPI-XK63730.snowflakecomputing.com/console#/monitoring/queries/detail?queryId=01bdc48f-0000-a176-0000-a58900013316","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.477616","level":"info","event":"25/07/18 09:19:55 INFO SparkConnectorContext$: Remove running query for app-20250718091916-0008 session: 182007829172298 queryId: 01bdc48f-0000-a176-0000-a58900013316","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.478170","level":"info","event":"25/07/18 09:19:55 INFO StageWriter$: First COPY command is done in 5.27 seconds at 2025-07-18T09:19:55.476614714, queryID is 01bdc48f-0000-a176-0000-a58900013316","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.485092","level":"info","event":"25/07/18 09:19:55 INFO StageWriter$: Succeed to write in 5.28 seconds at 2025-07-18T09:19:55.483656338","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.486817","level":"info","event":"25/07/18 09:19:55 INFO SnowflakeSQLStatement: Spark Connector Master: execute query with bind variable: alter table identifier(?) swap with identifier(?)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.673894","level":"info","event":"25/07/18 09:19:55 INFO SnowflakeSQLStatement: Spark Connector Master: execute query with bind variable: drop table identifier(?)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.872829","level":"info","event":"25/07/18 09:19:55 INFO StageWriter$: Spark Connector Master: Total job time is 29.28 seconds including read & upload time: 23.16 seconds and COPY time: 6.12 seconds.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.874874","level":"info","event":"25/07/18 09:19:55 WARN SnowflakeConnectorUtils$: Query pushdown is not supported because you are using Spark 3.4.0 with a connector designed to support Spark 3.3. Either use the version of Spark supported by the connector or install a version of the connector that supports your version of Spark.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.875077","level":"info","event":"25/07/18 09:19:55 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 8da053d44e9f:41325 in memory (size: 18.1 KiB, free: 434.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.877104","level":"info","event":"25/07/18 09:19:55 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.24.0.6:35799 in memory (size: 18.1 KiB, free: 434.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.878251","level":"info","event":"25/07/18 09:19:55 INFO ServerConnection$: Create ServerConnection with cached JDBC connection: 182007829172298","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:55.878433","level":"info","event":"25/07/18 09:19:55 INFO SnowflakeSQLStatement: Spark Connector Master: execute query with bind variable: select * from SILVER_DATA where 1 = 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:56.878039","level":"info","event":"25/07/18 09:19:56 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:56.878325","level":"info","event":"25/07/18 09:19:56 INFO SparkContext: SparkContext is stopping with exitCode 0.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:56.880001","level":"info","event":"25/07/18 09:19:56 WARN SparkConnectorContext$: Finish cancelling all queries for app-20250718091916-0008","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:56.880243","level":"info","event":"25/07/18 09:19:56 INFO ServerConnection$: Close all 1 cached connection.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:56.891900","level":"info","event":"25/07/18 09:19:56 INFO SparkUI: Stopped Spark web UI at http://8da053d44e9f:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:56.895315","level":"info","event":"25/07/18 09:19:56 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:56.895471","level":"info","event":"25/07/18 09:19:56 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.169166","level":"info","event":"25/07/18 09:19:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.179496","level":"info","event":"25/07/18 09:19:57 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.179648","level":"info","event":"25/07/18 09:19:57 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.182118","level":"info","event":"25/07/18 09:19:57 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.184183","level":"info","event":"25/07/18 09:19:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.192330","level":"info","event":"25/07/18 09:19:57 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.192518","level":"info","event":"25/07/18 09:19:57 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.192780","level":"info","event":"25/07/18 09:19:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-ce34f0eb-f950-4517-b8fc-7f79d84d1416/pyspark-6ca57f42-fd67-4e6f-8ec9-00c288d44bd9","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.196763","level":"info","event":"25/07/18 09:19:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-99cda429-59d5-4e1d-921f-bbe24105b8ed","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.199669","level":"info","event":"25/07/18 09:19:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-ce34f0eb-f950-4517-b8fc-7f79d84d1416","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.245337","level":"info","event":"Command exited with return code 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-18T09:19:57.245957","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('01981cd4-6176-7127-8a64-19e04c6b82bb'), task_id='silver_layer_snowflake', dag_id='retail_pipeline', run_id='manual__2025-07-18T09:18:57.380131+00:00', try_number=1, map_index=-1, hostname='47a9167a254f', context_carrier=None, task=<Task(BashOperator): silver_layer_snowflake>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=0, start_date=datetime.datetime(2025, 7, 18, 9, 19, 13, 716876, tzinfo=TzInfo(UTC)), end_date=None, is_mapped=False)","logger":"task"}

{"timestamp":"2025-07-15T06:23:12.595222","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-15T06:23:12.595683","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/upload_to_hdfs_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-15T06:23:12.608015","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:12.608584","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'docker exec retail-spark-master                        /opt/bitnami/spark/bin/spark-submit                        --master spark://spark-master:7077 /opt/spark-apps/scripts/data_preparation.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:12.616247","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:13.871598","level":"info","event":"25/07/15 06:23:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.436763","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.444277","level":"info","event":"25/07/15 06:23:14 INFO SparkContext: Running Spark version 3.1.1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.477180","level":"info","event":"25/07/15 06:23:14 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.477395","level":"info","event":"25/07/15 06:23:14 INFO ResourceUtils: No custom resources configured for spark.driver.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.477675","level":"info","event":"25/07/15 06:23:14 INFO ResourceUtils: ==============================================================","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.477926","level":"info","event":"25/07/15 06:23:14 INFO SparkContext: Submitted application: RetailSilver","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.497080","level":"info","event":"25/07/15 06:23:14 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.505287","level":"info","event":"25/07/15 06:23:14 INFO ResourceProfile: Limiting resource is cpu","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.505593","level":"info","event":"25/07/15 06:23:14 INFO ResourceProfileManager: Added ResourceProfile id: 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.543834","level":"info","event":"25/07/15 06:23:14 INFO SecurityManager: Changing view acls to: spark","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.543956","level":"info","event":"25/07/15 06:23:14 INFO SecurityManager: Changing modify acls to: spark","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.543998","level":"info","event":"25/07/15 06:23:14 INFO SecurityManager: Changing view acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.544027","level":"info","event":"25/07/15 06:23:14 INFO SecurityManager: Changing modify acls groups to:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.544055","level":"info","event":"25/07/15 06:23:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.724750","level":"info","event":"25/07/15 06:23:14 INFO Utils: Successfully started service 'sparkDriver' on port 44371.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.750922","level":"info","event":"25/07/15 06:23:14 INFO SparkEnv: Registering MapOutputTracker","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.779391","level":"info","event":"25/07/15 06:23:14 INFO SparkEnv: Registering BlockManagerMaster","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.798202","level":"info","event":"25/07/15 06:23:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.798348","level":"info","event":"25/07/15 06:23:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.802295","level":"info","event":"25/07/15 06:23:14 INFO SparkEnv: Registering BlockManagerMasterHeartbeat","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.814540","level":"info","event":"25/07/15 06:23:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-873cec88-faa8-4e90-b2e1-ac73cf878ea5","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.833717","level":"info","event":"25/07/15 06:23:14 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:14.847574","level":"info","event":"25/07/15 06:23:14 INFO SparkEnv: Registering OutputCommitCoordinator","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.026394","level":"info","event":"25/07/15 06:23:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.071596","level":"info","event":"25/07/15 06:23:15 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://9a3260e4aed2:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.225063","level":"info","event":"25/07/15 06:23:15 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://retail-spark-master:7077...","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.269267","level":"info","event":"25/07/15 06:23:15 INFO TransportClientFactory: Successfully created connection to retail-spark-master/172.24.0.4:7077 after 28 ms (0 ms spent in bootstraps)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.345011","level":"info","event":"25/07/15 06:23:15 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250715062315-0006","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.345240","level":"info","event":"25/07/15 06:23:15 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250715062315-0006/0 on worker-20250715054602-172.24.0.6-34599 (172.24.0.6:34599) with 12 core(s)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.348669","level":"info","event":"25/07/15 06:23:15 INFO StandaloneSchedulerBackend: Granted executor ID app-20250715062315-0006/0 on hostPort 172.24.0.6:34599 with 12 core(s), 1024.0 MiB RAM","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.351643","level":"info","event":"25/07/15 06:23:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45873.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.351822","level":"info","event":"25/07/15 06:23:15 INFO NettyBlockTransferService: Server created on 9a3260e4aed2:45873","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.353670","level":"info","event":"25/07/15 06:23:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.362000","level":"info","event":"25/07/15 06:23:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 9a3260e4aed2, 45873, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.365039","level":"info","event":"25/07/15 06:23:15 INFO BlockManagerMasterEndpoint: Registering block manager 9a3260e4aed2:45873 with 366.3 MiB RAM, BlockManagerId(driver, 9a3260e4aed2, 45873, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.367006","level":"info","event":"25/07/15 06:23:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 9a3260e4aed2, 45873, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.367996","level":"info","event":"25/07/15 06:23:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 9a3260e4aed2, 45873, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.387530","level":"info","event":"25/07/15 06:23:15 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250715062315-0006/0 is now RUNNING","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.552671","level":"info","event":"25/07/15 06:23:15 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.822074","level":"info","event":"25/07/15 06:23:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/opt/bitnami/spark/spark-warehouse').","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:15.822281","level":"info","event":"25/07/15 06:23:15 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:17.000951","level":"info","event":"25/07/15 06:23:16 INFO InMemoryFileIndex: It took 50 ms to list leaf files for 1 paths.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:17.167651","level":"info","event":"25/07/15 06:23:17 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.24.0.6:56614) with ID 0,  ResourceProfileId 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:17.265522","level":"info","event":"25/07/15 06:23:17 INFO BlockManagerMasterEndpoint: Registering block manager 172.24.0.6:43887 with 366.3 MiB RAM, BlockManagerId(0, 172.24.0.6, 43887, None)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:18.735301","level":"info","event":"25/07/15 06:23:18 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:18.740446","level":"info","event":"25/07/15 06:23:18 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, CustomerID#6)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:18.743415","level":"info","event":"25/07/15 06:23:18 INFO FileSourceStrategy: Output Data Schema: struct<InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: string ... 6 more fields>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.085170","level":"info","event":"25/07/15 06:23:19 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.110220","level":"info","event":"25/07/15 06:23:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.110379","level":"info","event":"25/07/15 06:23:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.112119","level":"info","event":"25/07/15 06:23:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.112270","level":"info","event":"25/07/15 06:23:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.112341","level":"info","event":"25/07/15 06:23:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.113821","level":"info","event":"25/07/15 06:23:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.538821","level":"info","event":"25/07/15 06:23:19 INFO CodeGenerator: Code generated in 177.923903 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.580403","level":"info","event":"25/07/15 06:23:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 303.1 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.625647","level":"info","event":"25/07/15 06:23:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 366.0 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.628063","level":"info","event":"25/07/15 06:23:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 9a3260e4aed2:45873 (size: 27.4 KiB, free: 366.3 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.630703","level":"info","event":"25/07/15 06:23:19 INFO SparkContext: Created broadcast 0 from parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.645094","level":"info","event":"25/07/15 06:23:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4284280 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.759140","level":"info","event":"25/07/15 06:23:19 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.770763","level":"info","event":"25/07/15 06:23:19 INFO DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 12 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.770928","level":"info","event":"25/07/15 06:23:19 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.770990","level":"info","event":"25/07/15 06:23:19 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.772669","level":"info","event":"25/07/15 06:23:19 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.776120","level":"info","event":"25/07/15 06:23:19 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.856818","level":"info","event":"25/07/15 06:23:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 182.6 KiB, free 365.8 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.860331","level":"info","event":"25/07/15 06:23:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 65.5 KiB, free 365.7 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.860821","level":"info","event":"25/07/15 06:23:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 9a3260e4aed2:45873 (size: 65.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.861223","level":"info","event":"25/07/15 06:23:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.875006","level":"info","event":"25/07/15 06:23:19 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.875577","level":"info","event":"25/07/15 06:23:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 12 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.903992","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.24.0.6, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.907013","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.24.0.6, executor 0, partition 1, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.907816","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (172.24.0.6, executor 0, partition 2, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.908947","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (172.24.0.6, executor 0, partition 3, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.910127","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (172.24.0.6, executor 0, partition 4, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.911345","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5) (172.24.0.6, executor 0, partition 5, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.912076","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6) (172.24.0.6, executor 0, partition 6, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.912531","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7) (172.24.0.6, executor 0, partition 7, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.913202","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8) (172.24.0.6, executor 0, partition 8, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.914343","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9) (172.24.0.6, executor 0, partition 9, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.914459","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10) (172.24.0.6, executor 0, partition 10, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:19.914530","level":"info","event":"25/07/15 06:23:19 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11) (172.24.0.6, executor 0, partition 11, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:20.164299","level":"info","event":"25/07/15 06:23:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.24.0.6:43887 (size: 65.5 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:21.491000","level":"info","event":"25/07/15 06:23:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.24.0.6:43887 (size: 27.4 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:23.006584","level":"info","event":"25/07/15 06:23:22 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 3084 ms on 172.24.0.6 (executor 0) (1/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:23.691194","level":"info","event":"25/07/15 06:23:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3792 ms on 172.24.0.6 (executor 0) (2/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:23.857287","level":"info","event":"25/07/15 06:23:23 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 3948 ms on 172.24.0.6 (executor 0) (3/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:23.929376","level":"info","event":"25/07/15 06:23:23 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 4004 ms on 172.24.0.6 (executor 0) (4/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:23.930084","level":"info","event":"25/07/15 06:23:23 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 4015 ms on 172.24.0.6 (executor 0) (5/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:23.986158","level":"info","event":"25/07/15 06:23:23 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 4072 ms on 172.24.0.6 (executor 0) (6/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:23.994267","level":"info","event":"25/07/15 06:23:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 4087 ms on 172.24.0.6 (executor 0) (7/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.018750","level":"info","event":"25/07/15 06:23:24 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 4107 ms on 172.24.0.6 (executor 0) (8/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.034244","level":"info","event":"25/07/15 06:23:24 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 4125 ms on 172.24.0.6 (executor 0) (9/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.092034","level":"info","event":"25/07/15 06:23:24 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 4178 ms on 172.24.0.6 (executor 0) (10/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.415029","level":"info","event":"25/07/15 06:23:24 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 4501 ms on 172.24.0.6 (executor 0) (11/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.425207","level":"info","event":"25/07/15 06:23:24 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 4518 ms on 172.24.0.6 (executor 0) (12/12)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.427167","level":"info","event":"25/07/15 06:23:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.428174","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 4.631 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.432089","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.432207","level":"info","event":"25/07/15 06:23:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.435589","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 4.675245 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.564423","level":"info","event":"25/07/15 06:23:24 INFO FileFormatWriter: Write Job 0f71de85-14d7-454c-a1d5-0dcb4f98749d committed.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.567425","level":"info","event":"25/07/15 06:23:24 INFO FileFormatWriter: Finished processing stats for write job 0f71de85-14d7-454c-a1d5-0dcb4f98749d.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.621375","level":"info","event":"25/07/15 06:23:24 INFO FileSourceStrategy: Pushed Filters:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.621559","level":"info","event":"25/07/15 06:23:24 INFO FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, CustomerID#6)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.621637","level":"info","event":"25/07/15 06:23:24 INFO FileSourceStrategy: Output Data Schema: struct<InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: string ... 6 more fields>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.682118","level":"info","event":"25/07/15 06:23:24 INFO CodeGenerator: Code generated in 23.310035 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.686369","level":"info","event":"25/07/15 06:23:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 303.1 KiB, free 365.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.692832","level":"info","event":"25/07/15 06:23:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 365.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.693610","level":"info","event":"25/07/15 06:23:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 9a3260e4aed2:45873 (size: 27.4 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.694692","level":"info","event":"25/07/15 06:23:24 INFO SparkContext: Created broadcast 2 from showString at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.696510","level":"info","event":"25/07/15 06:23:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4284280 bytes, open cost is considered as scanning 4194304 bytes.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.711677","level":"info","event":"25/07/15 06:23:24 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.712751","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.712897","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.712969","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: Parents of final stage: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.713014","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: Missing parents: List()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.713773","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.717222","level":"info","event":"25/07/15 06:23:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 19.3 KiB, free 365.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.718550","level":"info","event":"25/07/15 06:23:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 365.4 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.718986","level":"info","event":"25/07/15 06:23:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 9a3260e4aed2:45873 (size: 8.8 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.719356","level":"info","event":"25/07/15 06:23:24 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1383","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.719844","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.719926","level":"info","event":"25/07/15 06:23:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.720927","level":"info","event":"25/07/15 06:23:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 12) (172.24.0.6, executor 0, partition 0, ANY, 4876 bytes) taskResourceAssignments Map()","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.737035","level":"info","event":"25/07/15 06:23:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.24.0.6:43887 (size: 8.8 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.831107","level":"info","event":"25/07/15 06:23:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.24.0.6:43887 (size: 27.4 KiB, free: 366.2 MiB)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.849452","level":"info","event":"25/07/15 06:23:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 12) in 129 ms on 172.24.0.6 (executor 0) (1/1)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.849671","level":"info","event":"25/07/15 06:23:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.849884","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 0.135 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.849988","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.850042","level":"info","event":"25/07/15 06:23:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.850479","level":"info","event":"25/07/15 06:23:24 INFO DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 0.138830 s","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.883059","level":"info","event":"25/07/15 06:23:24 INFO CodeGenerator: Code generated in 16.721756 ms","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.892415","level":"info","event":"+----------+----------+--------------------+--------+-------------------+----------+-----------+--------------+-------+---------+","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.892788","level":"info","event":"|invoice_no|stock_code|         description|quantity|       invoice_date|unit_price|customer_id|       country|revenue|is_return|","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.892839","level":"info","event":"+----------+----------+--------------------+--------+-------------------+----------+-----------+--------------+-------+---------+","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.892869","level":"info","event":"|    536365|    85123A|WHITE HANGING HEA...|       6|12/01/2010 08:26:00|      2.55|      17850|United Kingdom|   15.0|        0|","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.892894","level":"info","event":"|    536365|     71053| WHITE METAL LANTERN|       6|12/01/2010 08:26:00|      3.39|      17850|United Kingdom|   20.0|        0|","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.892946","level":"info","event":"|    536365|    84406B|CREAM CUPID HEART...|       8|12/01/2010 08:26:00|      2.75|      17850|United Kingdom|   22.0|        0|","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.892986","level":"info","event":"|    536365|    84029G|KNITTED UNION FLA...|       6|12/01/2010 08:26:00|      3.39|      17850|United Kingdom|   20.0|        0|","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.893011","level":"info","event":"|    536365|    84029E|RED WOOLLY HOTTIE...|       6|12/01/2010 08:26:00|      3.39|      17850|United Kingdom|   20.0|        0|","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.893034","level":"info","event":"+----------+----------+--------------------+--------+-------------------+----------+-----------+--------------+-------+---------+","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.893059","level":"info","event":"only showing top 5 rows","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.893132","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.915220","level":"info","event":"25/07/15 06:23:24 INFO SparkContext: Invoking stop() from shutdown hook","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.924426","level":"info","event":"25/07/15 06:23:24 INFO SparkUI: Stopped Spark web UI at http://9a3260e4aed2:4040","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.927542","level":"info","event":"25/07/15 06:23:24 INFO StandaloneSchedulerBackend: Shutting down all executors","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.927727","level":"info","event":"25/07/15 06:23:24 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.944553","level":"info","event":"25/07/15 06:23:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.955323","level":"info","event":"25/07/15 06:23:24 INFO MemoryStore: MemoryStore cleared","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.955460","level":"info","event":"25/07/15 06:23:24 INFO BlockManager: BlockManager stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.961726","level":"info","event":"25/07/15 06:23:24 INFO BlockManagerMaster: BlockManagerMaster stopped","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.964177","level":"info","event":"25/07/15 06:23:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.972028","level":"info","event":"25/07/15 06:23:24 INFO SparkContext: Successfully stopped SparkContext","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.972166","level":"info","event":"25/07/15 06:23:24 INFO ShutdownHookManager: Shutdown hook called","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.972306","level":"info","event":"25/07/15 06:23:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-e837ca8c-b766-4340-9522-9b71ddd48d90","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.976002","level":"info","event":"25/07/15 06:23:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-e837ca8c-b766-4340-9522-9b71ddd48d90/pyspark-19ce3edd-d02a-41e1-a9bf-e536106e99e4","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:24.979031","level":"info","event":"25/07/15 06:23:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-f5a03667-bbac-4a81-ab11-f7998d3e3fec","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:25.136301","level":"info","event":"Command exited with return code 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"}
{"timestamp":"2025-07-15T06:23:25.136914","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('01980cc0-5d57-78fe-bc5b-ae63c1c2ab80'), task_id='silver_layer', dag_id='retail_pipeline', run_id='manual__2025-07-15T06:23:10.122276+00:00', try_number=1, map_index=-1, hostname='df937ae4f2c6', context_carrier=None, task=<Task(BashOperator): silver_layer>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=0, start_date=datetime.datetime(2025, 7, 15, 6, 23, 12, 558659, tzinfo=TzInfo(UTC)), end_date=None, is_mapped=False)","logger":"task"}
